{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "from scipy.stats import skew, kurtosis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "dGsUSZWeTYlv",
        "outputId": "e8aa3fee-e1d9-46f9-b1c9-ca6a9b5ea5f0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "no errors (yet)\n"
          ]
        }
      ],
      "source": [
        "df = pd.read_csv('path')\n",
        "\n",
        "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "\n",
        "def preprocess_text(text):\n",
        "    return text.lower().strip()\n",
        "\n",
        "train_df['Processed_Review'] = train_df['Review'].apply(preprocess_text)\n",
        "test_df['Processed_Review'] = test_df['Review'].apply(preprocess_text)\n",
        "\n",
        "rating_min = train_df['Rating'].min()\n",
        "rating_max = train_df['Rating'].max()\n",
        "train_df['Normalized_Rating'] = (train_df['Rating'] - rating_min) / (rating_max - rating_min)\n",
        "test_df['Normalized_Rating'] = (test_df['Rating'] - rating_min) / (rating_max - rating_min)\n",
        "\n",
        "# loading the pre-trained  model and tokenizer\n",
        "model_name = 'distilbert-base-uncased'\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "model = AutoModel.from_pretrained(model_name)\n",
        "\n",
        "# encode text using the transformer and maintain the output shape\n",
        "def encode_text(text, max_length=128):\n",
        "    inputs = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n",
        "    with torch.no_grad():\n",
        "        outputs = model(**inputs)\n",
        "    return outputs.last_hidden_state.mean(dim=1).squeeze().numpy()  # MAKIGN SURE TO MAINTAIN THE SHAPE (768)\n",
        "\n",
        "# encoding the preprocessed reviews\n",
        "train_df['Encoded_Review'] = train_df['Processed_Review'].apply(lambda x: encode_text(x))\n",
        "test_df['Encoded_Review'] = test_df['Processed_Review'].apply(lambda x: encode_text(x))\n",
        "\n",
        "print(\"no errors (yet)\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "uJSjJCoATfPf"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "# adding an attention layer to improve the performance of the model\n",
        "class AttentionLayer(layers.Layer):\n",
        "    def __init__(self, **kwargs):\n",
        "        super(AttentionLayer, self).__init__(**kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.W = self.add_weight(name=\"att_weight\", shape=(input_shape[-1], 1),\n",
        "                                 initializer=\"normal\")\n",
        "        self.b = self.add_weight(name=\"att_bias\", shape=(input_shape[1], 1),\n",
        "                                 initializer=\"zeros\")\n",
        "        super(AttentionLayer, self).build(input_shape)\n",
        "\n",
        "    def call(self, x):\n",
        "        et = tf.squeeze(tf.tanh(tf.matmul(x, self.W) + self.b), axis=-1)\n",
        "        at = tf.nn.softmax(et)\n",
        "        at = tf.expand_dims(at, axis=-1)\n",
        "        output = x * at\n",
        "        return tf.reduce_sum(output, axis=1)\n",
        "\n",
        "# creating the multimodal class that combines the numerical and text data with modalitiy specific encoders and decoders\n",
        "class MultimodalVAE(keras.Model):\n",
        "    def __init__(self, numerical_dim, text_dim, latent_dim):\n",
        "        super(MultimodalVAE, self).__init__()\n",
        "        self.numerical_encoder = self.build_numerical_encoder(numerical_dim, latent_dim)\n",
        "        self.text_encoder = self.build_text_encoder(text_dim, latent_dim)\n",
        "        self.numerical_decoder = self.build_numerical_decoder(latent_dim, numerical_dim)\n",
        "        self.text_decoder = self.build_text_decoder(latent_dim, text_dim)\n",
        "        self.sampling = layers.Lambda(self.sample, output_shape=(latent_dim,))\n",
        "        self.latent_dim = latent_dim\n",
        "\n",
        "    def build_numerical_encoder(self, numerical_dim, latent_dim):\n",
        "        inputs = keras.Input(shape=(numerical_dim,), dtype=tf.float32)\n",
        "        x = layers.Dense(64, activation=\"relu\")(inputs)\n",
        "        x = layers.Dense(32, activation=\"relu\")(x)\n",
        "        z_mean = layers.Dense(latent_dim)(x)\n",
        "        z_log_var = layers.Dense(latent_dim)(x)\n",
        "        return keras.Model(inputs, [z_mean, z_log_var])\n",
        "\n",
        "    def build_text_encoder(self, text_dim, latent_dim):\n",
        "        inputs = keras.Input(shape=(text_dim,), dtype=tf.float32)\n",
        "        x = layers.Dense(128, activation=\"relu\")(inputs)\n",
        "        x = layers.Reshape((128, -1))(x)\n",
        "        x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "        x = layers.GlobalAveragePooling1D()(x)\n",
        "        x = layers.Dense(32, activation=\"relu\")(x)\n",
        "        z_mean = layers.Dense(latent_dim)(x)\n",
        "        z_log_var = layers.Dense(latent_dim)(x)\n",
        "        return keras.Model(inputs, [z_mean, z_log_var])\n",
        "\n",
        "    def build_numerical_decoder(self, latent_dim, numerical_dim):\n",
        "        inputs = keras.Input(shape=(latent_dim,))\n",
        "        x = layers.Dense(32, activation=\"relu\")(inputs)\n",
        "        x = layers.Dense(64, activation=\"relu\")(x)\n",
        "        outputs = layers.Dense(numerical_dim)(x)\n",
        "        return keras.Model(inputs, outputs)\n",
        "\n",
        "    def build_text_decoder(self, latent_dim, text_dim):\n",
        "        inputs = keras.Input(shape=(latent_dim,))\n",
        "        x = layers.RepeatVector(128)(inputs)  # adjusting to 128 timesteps\n",
        "        x = layers.LSTM(128, return_sequences=True)(x)\n",
        "        x = AttentionLayer()(x)\n",
        "        x = layers.Dense(64, activation=\"relu\")(x)\n",
        "        x = layers.RepeatVector(text_dim)(x)\n",
        "        outputs = layers.TimeDistributed(layers.Dense(10000, activation=\"softmax\"))(x)\n",
        "        return keras.Model(inputs, outputs)\n",
        "\n",
        "    def sample(self, args):\n",
        "        z_mean, z_log_var = args\n",
        "        epsilon = tf.random.normal(shape=tf.shape(z_mean))\n",
        "        return z_mean + tf.exp(0.5 * z_log_var) * epsilon\n",
        "\n",
        "    def call(self, inputs):\n",
        "        numerical_input, text_input = inputs\n",
        "        numerical_z_mean, numerical_z_log_var = self.numerical_encoder(tf.cast(numerical_input, tf.float32))\n",
        "        text_z_mean, text_z_log_var = self.text_encoder(tf.cast(text_input, tf.float32))\n",
        "\n",
        "        z_mean = (numerical_z_mean + text_z_mean) / 2\n",
        "        z_log_var = (numerical_z_log_var + text_z_log_var) / 2\n",
        "        z = self.sampling((z_mean, z_log_var))\n",
        "\n",
        "        numerical_output = self.numerical_decoder(z)\n",
        "        text_output = self.text_decoder(z)\n",
        "\n",
        "        return numerical_output, text_output, z_mean, z_log_var\n",
        "\n",
        "    def decode_numerical(self, z):\n",
        "        return self.numerical_decoder(z)\n",
        "\n",
        "    def decode_text(self, z):\n",
        "        return self.text_decoder(z)\n",
        "\n",
        "# compiling the model with the Adam optimizer\n",
        "numerical_dim = 1\n",
        "text_dim = 768\n",
        "latent_dim = 64\n",
        "vae = MultimodalVAE(numerical_dim, text_dim, latent_dim)\n",
        "\n",
        "vae.compile(optimizer=keras.optimizers.Adam())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "ZmX52vUxThOF"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Improved Genetic Algorithm defined and original data prepared.\n",
            "everything ran so far well done\n"
          ]
        }
      ],
      "source": [
        "import random\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "#creating the evolutionary algorithm class \n",
        "class Individual:\n",
        "    def __init__(self, latent_vector):\n",
        "        self.latent_vector = latent_vector\n",
        "        self.fitness = None\n",
        "\n",
        "\n",
        "def improved_genetic_algorithm(original_ratings, population_size=200, num_generations=70, crossover_rate=0.7, mutation_rate=0.01): #changing number of gens and stuff\n",
        "    # compute the statistical properties of the original data\n",
        "    original_stats = {\n",
        "        'mean': original_ratings.mean(),\n",
        "        'variance': original_ratings.var(),\n",
        "        'skewness': skew(original_ratings),\n",
        "        'kurtosis': kurtosis(original_ratings)\n",
        "    }\n",
        "\n",
        "    # generate the initial population of synthetic datasets\n",
        "    initial_population = [np.random.normal(loc=original_stats['mean'], scale=np.sqrt(original_stats['variance']), size=len(original_ratings)) for _ in range(population_size)]\n",
        "\n",
        "    # Fitness function\n",
        "    def fitness_function(synthetic_data, original_stats):\n",
        "        mean_diff = (synthetic_data.mean() - original_stats['mean']) ** 2\n",
        "        variance_diff = (synthetic_data.var() - original_stats['variance']) ** 2\n",
        "        skewness_diff = (skew(synthetic_data) - original_stats['skewness']) ** 2\n",
        "        kurtosis_diff = (kurtosis(synthetic_data) - original_stats['kurtosis']) ** 2\n",
        "        return mean_diff + variance_diff + skewness_diff + kurtosis_diff\n",
        "\n",
        "    # evaluate the fitness of the initial population\n",
        "    fitness_scores = [fitness_function(synthetic_data, original_stats) for synthetic_data in initial_population]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    # MAIN LOOP  - EVOLUTIONARY ALGORITHM\n",
        "    for generation in range(num_generations):\n",
        "        # Selection (using tournament selection)\n",
        "        selected_population = []\n",
        "        for _ in range(population_size):\n",
        "            competitors = np.random.choice(population_size, size=3, replace=False)\n",
        "            winner = min(competitors, key=lambda i: fitness_scores[i])\n",
        "            selected_population.append(initial_population[winner])\n",
        "\n",
        "        # Crossover\n",
        "        new_population = []\n",
        "        for i in range(0, population_size, 2):\n",
        "            parent1 = selected_population[i]\n",
        "            parent2 = selected_population[i + 1]\n",
        "            if np.random.rand() < crossover_rate:\n",
        "                crossover_point = np.random.randint(1, len(parent1) - 1)\n",
        "                child1 = np.concatenate((parent1[:crossover_point], parent2[crossover_point:]))\n",
        "                child2 = np.concatenate((parent2[:crossover_point], parent1[crossover_point:]))\n",
        "            else:\n",
        "                child1, child2 = parent1, parent2\n",
        "            new_population.extend([child1, child2])\n",
        "\n",
        "        # Mutation\n",
        "        for i in range(population_size):\n",
        "            if np.random.rand() < mutation_rate:\n",
        "                mutation_point = np.random.randint(len(new_population[i]))\n",
        "                new_population[i][mutation_point] += np.random.normal()\n",
        "\n",
        "        # evaluating the new population\n",
        "        fitness_scores = [fitness_function(synthetic_data, original_stats) for synthetic_data in new_population]\n",
        "        initial_population = new_population\n",
        "\n",
        "        # printing progress\n",
        "        best_fitness = min(fitness_scores)\n",
        "        print(f\"Generation {generation + 1}/{num_generations}, Best Fitness: {best_fitness:.4f}\")\n",
        "\n",
        "    # selecting the best synthetic dataset\n",
        "    best_synthetic_data = initial_population[np.argmin(fitness_scores)]\n",
        "\n",
        "    return best_synthetic_data\n",
        "\n",
        "# prepare original data for the EA\n",
        "original_ratings = train_df['Rating'].values\n",
        "\n",
        "print(\"done\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# 12 minutes with 100 population size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "wf0HMZk_Tns5"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/thomas/miniconda3/envs/TF/lib/python3.11/site-packages/transformers/data/datasets/language_modeling.py:53: FutureWarning: This dataset will be removed from the library soon, preprocessing should be handled with the ðŸ¤— Datasets library. You can have a look at this example script for pointers: https://github.com/huggingface/transformers/blob/main/examples/pytorch/language-modeling/run_mlm.py\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='360' max='360' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [360/360 02:28, Epoch 30/30]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generating synthetic data...\n",
            "Generation 1/50, Best Fitness: 0.0031\n",
            "Generation 2/50, Best Fitness: 0.0061\n",
            "Generation 3/50, Best Fitness: 0.0055\n",
            "Generation 4/50, Best Fitness: 0.0013\n",
            "Generation 5/50, Best Fitness: 0.0013\n",
            "Generation 6/50, Best Fitness: 0.0013\n",
            "Generation 7/50, Best Fitness: 0.0013\n",
            "Generation 8/50, Best Fitness: 0.0012\n",
            "Generation 9/50, Best Fitness: 0.0012\n",
            "Generation 10/50, Best Fitness: 0.0012\n",
            "Generation 11/50, Best Fitness: 0.0012\n",
            "Generation 12/50, Best Fitness: 0.0012\n",
            "Generation 13/50, Best Fitness: 0.0012\n",
            "Generation 14/50, Best Fitness: 0.0012\n",
            "Generation 15/50, Best Fitness: 0.0012\n",
            "Generation 16/50, Best Fitness: 0.0012\n",
            "Generation 17/50, Best Fitness: 0.0012\n",
            "Generation 18/50, Best Fitness: 0.0012\n",
            "Generation 19/50, Best Fitness: 0.0012\n",
            "Generation 20/50, Best Fitness: 0.0012\n",
            "Generation 21/50, Best Fitness: 0.0012\n",
            "Generation 22/50, Best Fitness: 0.0012\n",
            "Generation 23/50, Best Fitness: 0.0012\n",
            "Generation 24/50, Best Fitness: 0.0012\n",
            "Generation 25/50, Best Fitness: 0.0012\n",
            "Generation 26/50, Best Fitness: 0.0012\n",
            "Generation 27/50, Best Fitness: 0.0012\n",
            "Generation 28/50, Best Fitness: 0.0012\n",
            "Generation 29/50, Best Fitness: 0.0012\n",
            "Generation 30/50, Best Fitness: 0.0012\n",
            "Generation 31/50, Best Fitness: 0.0012\n",
            "Generation 32/50, Best Fitness: 0.0012\n",
            "Generation 33/50, Best Fitness: 0.0012\n",
            "Generation 34/50, Best Fitness: 0.0012\n",
            "Generation 35/50, Best Fitness: 0.0012\n",
            "Generation 36/50, Best Fitness: 0.0012\n",
            "Generation 37/50, Best Fitness: 0.0012\n",
            "Generation 38/50, Best Fitness: 0.0011\n",
            "Generation 39/50, Best Fitness: 0.0011\n",
            "Generation 40/50, Best Fitness: 0.0011\n",
            "Generation 41/50, Best Fitness: 0.0011\n",
            "Generation 42/50, Best Fitness: 0.0011\n",
            "Generation 43/50, Best Fitness: 0.0011\n",
            "Generation 44/50, Best Fitness: 0.0011\n",
            "Generation 45/50, Best Fitness: 0.0011\n",
            "Generation 46/50, Best Fitness: 0.0011\n",
            "Generation 47/50, Best Fitness: 0.0011\n",
            "Generation 48/50, Best Fitness: 0.0011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generation 49/50, Best Fitness: 0.0011\n",
            "Generation 50/50, Best Fitness: 0.0011\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Synthetic data generated.\n",
            "                                              Review    Rating\n",
            "0  \\n\"the last of the lambs\", the last lamban, is...  0.664372\n",
            "1  the king of kings, a tyrant is visited by the ...  5.311334\n",
            "2  the film is based on the bestselling novel by ...  5.000716\n",
            "3  the place where a young woman is murdered and ...  6.294413\n",
            "4  theresa chiau, a young woman with special need...  8.658176\n"
          ]
        }
      ],
      "source": [
        "import tempfile\n",
        "import os\n",
        "from transformers import GPT2LMHeadModel, GPT2Tokenizer, TextDataset, DataCollatorForLanguageModeling\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "# using gpt2 for THE the text generation\n",
        "model_name = 'gpt2'\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "model = GPT2LMHeadModel.from_pretrained(model_name)\n",
        "\n",
        "# preparation fro fine tuning on data above\n",
        "def prepare_data_for_gpt2(df, text_column):\n",
        "    texts = df[text_column].tolist()\n",
        "\n",
        "    # using a temp file - making sure to use utf 8\n",
        "    with tempfile.NamedTemporaryFile(mode='w+', delete=False, encoding='utf-8') as f:\n",
        "        for text in texts:\n",
        "            f.write(f\"{text}\\n\")\n",
        "\n",
        "    dataset = TextDataset(\n",
        "        tokenizer=tokenizer,\n",
        "        file_path=f.name,\n",
        "        block_size=128\n",
        "    )\n",
        "\n",
        "    # remove the temp file\n",
        "    os.unlink(f.name)\n",
        "\n",
        "    return dataset\n",
        "\n",
        "train_dataset = prepare_data_for_gpt2(train_df, 'Processed_Review')\n",
        "\n",
        "# playing with batch size helps with perf\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='./results',\n",
        "    num_train_epochs=30, # changed from 3 to 30\n",
        "    per_device_train_batch_size=16,\n",
        "    save_steps=10_000,\n",
        "    save_total_limit=2,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    data_collator=DataCollatorForLanguageModeling(tokenizer=tokenizer, mlm=False),\n",
        "    train_dataset=train_dataset,\n",
        ")\n",
        "\n",
        "trainer.train()\n",
        "\n",
        "# making sure to move the model to my GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# MAIN GENERATION FUNCTION\n",
        "\n",
        "def generate_multiple_texts_and_ratings(best_latent_vector, vae, tokenizer, model, device, original_ratings, num_reviews=100, max_length=100):\n",
        "    synthetic_reviews = []\n",
        "\n",
        "    # generating the synthetic ratings using the improved EA\n",
        "    synthetic_ratings = improved_genetic_algorithm(original_ratings, population_size=200, num_generations=100)\n",
        "\n",
        "    for i in range(num_reviews):\n",
        "        # perturb the best latent vector slightly\n",
        "        perturbed_vector = best_latent_vector + np.random.normal(0, 0.1, vae.latent_dim).astype(np.float32)\n",
        "        perturbed_vector = np.array([perturbed_vector])\n",
        "\n",
        "        input_ids = tokenizer.encode(tokenizer.bos_token, return_tensors='pt').to(device)\n",
        "        attention_mask = torch.ones(input_ids.shape, dtype=torch.long).to(device)\n",
        "\n",
        "        output = model.generate(\n",
        "            input_ids=input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            max_length=max_length,\n",
        "            num_return_sequences=1,\n",
        "            no_repeat_ngram_size=2,\n",
        "            do_sample=True,\n",
        "            top_k=50,\n",
        "            top_p=0.95,\n",
        "            temperature=0.7\n",
        "        )\n",
        "\n",
        "        review = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "        synthetic_reviews.append(review)\n",
        "\n",
        "    return synthetic_reviews, synthetic_ratings\n",
        "\n",
        "\n",
        "\n",
        "print(\"generating synthetic data\")\n",
        "\n",
        "# generating the synthetic data\n",
        "synthetic_ratings = improved_genetic_algorithm(original_ratings, population_size=100, num_generations=50)\n",
        "\n",
        "# generating synthetic reviews using the now fine tuned GPT2\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "synthetic_reviews = []\n",
        "for _ in range(len(synthetic_ratings)):\n",
        "    input_ids = tokenizer.encode(tokenizer.bos_token, return_tensors='pt').to(device)\n",
        "    attention_mask = torch.ones(input_ids.shape, dtype=torch.long).to(device)\n",
        "\n",
        "    output = model.generate(\n",
        "        input_ids=input_ids,\n",
        "        attention_mask=attention_mask,\n",
        "        max_length=100,\n",
        "        num_return_sequences=1,\n",
        "        no_repeat_ngram_size=2,\n",
        "        do_sample=True,\n",
        "        top_k=50,\n",
        "        top_p=0.95,\n",
        "        temperature=0.7\n",
        "    )\n",
        "\n",
        "    review = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "    synthetic_reviews.append(review)\n",
        "\n",
        "# new df with synthetic data\n",
        "synthetic_df = pd.DataFrame({\n",
        "    'Review': synthetic_reviews,\n",
        "    'Rating': synthetic_ratings\n",
        "})\n",
        "\n",
        "print(\"done\")\n",
        "print(synthetic_df.head())\n",
        "\n",
        "# ENTIRE SCRIPT RUNTIME - SUB 5 MINUTES WITH GPU\n",
        "\n",
        "# 8 minutes with 20 epochs and 16 batch size\n",
        "\n",
        "# 11 minutes with 30 epochs and 16 batch size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "CbbnvMNaTzmA"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>\\n\"the last of the lambs\", the last lamban, is...</td>\n",
              "      <td>0.664372</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>the king of kings, a tyrant is visited by the ...</td>\n",
              "      <td>5.311334</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>the film is based on the bestselling novel by ...</td>\n",
              "      <td>5.000716</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>the place where a young woman is murdered and ...</td>\n",
              "      <td>6.294413</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>theresa chiau, a young woman with special need...</td>\n",
              "      <td>8.658176</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review    Rating\n",
              "0  \\n\"the last of the lambs\", the last lamban, is...  0.664372\n",
              "1  the king of kings, a tyrant is visited by the ...  5.311334\n",
              "2  the film is based on the bestselling novel by ...  5.000716\n",
              "3  the place where a young woman is murdered and ...  6.294413\n",
              "4  theresa chiau, a young woman with special need...  8.658176"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "synthetic_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [],
      "source": [
        "synthetic_df.to_csv('path')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>404.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.429208</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.759889</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.600000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.500000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Rating\n",
              "count  404.000000\n",
              "mean     5.429208\n",
              "std      1.759889\n",
              "min      1.000000\n",
              "25%      4.500000\n",
              "50%      5.600000\n",
              "75%      6.500000\n",
              "max     10.000000"
            ]
          },
          "execution_count": 31,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>323.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>5.417642</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>1.768667</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>-0.529100</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>4.363274</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>5.349215</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>6.600756</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>10.180781</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           Rating\n",
              "count  323.000000\n",
              "mean     5.417642\n",
              "std      1.768667\n",
              "min     -0.529100\n",
              "25%      4.363274\n",
              "50%      5.349215\n",
              "75%      6.600756\n",
              "max     10.180781"
            ]
          },
          "execution_count": 33,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "synthetic_df.describe()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "jJETvoHAT09E"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Review</th>\n",
              "      <th>Rating</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Mismatched travellers are stranded overnight a...</td>\n",
              "      <td>8.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>In 1900, strong-willed widow Lucy Muir goes to...</td>\n",
              "      <td>7.7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>In 1867, a gang led by James \"Stretch\" Dawson ...</td>\n",
              "      <td>6.9</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Reclusive Dr. Zorba has died and left his mans...</td>\n",
              "      <td>5.8</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The twisted Richard III is haunted by the ghos...</td>\n",
              "      <td>6.2</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              Review  Rating\n",
              "0  Mismatched travellers are stranded overnight a...     8.0\n",
              "1  In 1900, strong-willed widow Lucy Muir goes to...     7.7\n",
              "2  In 1867, a gang led by James \"Stretch\" Dawson ...     6.9\n",
              "3  Reclusive Dr. Zorba has died and left his mans...     5.8\n",
              "4  The twisted Richard III is haunted by the ghos...     6.2"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V7PHGiONvhuS"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
